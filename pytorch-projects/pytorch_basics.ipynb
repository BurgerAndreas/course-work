{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(3, 4)\n",
    "t = torch.ones_like(t)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.Size([2, 3])\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "t = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(t.device)\n",
    "print(t.shape)\n",
    "print(t[0, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in, d_out = 5, 3 # Input and output dimensions\n",
    "lin = nn.Linear(d_in, d_out) # Linear layer with 5 inputs and 3 outputs\n",
    "relu = nn.ReLU() # ReLU activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 4\n",
    "x = torch.rand(channels, d_in) # Input tensor\n",
    "\n",
    "# Forward pass\n",
    "y = relu(lin(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_h = 2 # Hidden layer dimension\n",
    "mlp = nn.Sequential(nn.Linear(d_in, d_h), nn.BatchNorm1d(d_h), nn.ReLU(), \n",
    "                    nn.Linear(d_h, d_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass\n",
    "y = mlp(x)\n",
    "y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12a5d9430>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random generator with fixed seed\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(channels, d_in, generator=g) # Input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = torch.rand(channels, d_out, generator=g) # True output tensor\n",
    "y_true = torch.zeros(channels, d_out) # True output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_opt = optim.Adam(mlp.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 4.132096290588379\n",
      "Epoch 1: 1.7699825763702393\n",
      "Epoch 2: 0.6587584018707275\n",
      "Epoch 3: 0.19137465953826904\n",
      "Epoch 4: 0.039265070110559464\n",
      "Epoch 5: 0.04842814803123474\n",
      "Epoch 6: 0.10276862978935242\n",
      "Epoch 7: 0.1415027678012848\n",
      "Epoch 8: 0.16058887541294098\n",
      "Epoch 9: 0.16690826416015625\n",
      "Epoch 10: 0.17378759384155273\n",
      "Epoch 11: 0.17818835377693176\n",
      "Epoch 12: 0.1788991540670395\n",
      "Epoch 13: 0.17188221216201782\n",
      "Epoch 14: 0.15410096943378448\n",
      "Epoch 15: 0.12613330781459808\n",
      "Epoch 16: 0.09224522113800049\n",
      "Epoch 17: 0.058732956647872925\n",
      "Epoch 18: 0.03157965838909149\n",
      "Epoch 19: 0.014402243308722973\n",
      "Epoch 20: 0.007599662058055401\n",
      "Epoch 21: 0.00899957399815321\n",
      "Epoch 22: 0.015331693924963474\n",
      "Epoch 23: 0.023510247468948364\n",
      "Epoch 24: 0.03125907480716705\n",
      "Epoch 25: 0.03718496859073639\n",
      "Epoch 26: 0.04054369777441025\n",
      "Epoch 27: 0.04095907881855965\n",
      "Epoch 28: 0.03834375739097595\n",
      "Epoch 29: 0.033051908016204834\n",
      "Epoch 30: 0.02600446343421936\n",
      "Epoch 31: 0.018529649823904037\n",
      "Epoch 32: 0.01194830983877182\n",
      "Epoch 33: 0.007148445583879948\n",
      "Epoch 34: 0.004375542514026165\n",
      "Epoch 35: 0.0033236811868846416\n",
      "Epoch 36: 0.0034477964509278536\n",
      "Epoch 37: 0.004285093396902084\n",
      "Epoch 38: 0.005576782859861851\n",
      "Epoch 39: 0.0071527692489326\n",
      "Epoch 40: 0.00873537827283144\n",
      "Epoch 41: 0.009866720996797085\n",
      "Epoch 42: 0.01005096361041069\n",
      "Epoch 43: 0.009028180502355099\n",
      "Epoch 44: 0.0069814324378967285\n",
      "Epoch 45: 0.004507672507315874\n",
      "Epoch 46: 0.002344271633774042\n",
      "Epoch 47: 0.0010158051736652851\n",
      "Epoch 48: 0.0006191027350723743\n",
      "Epoch 49: 0.000865770154632628\n",
      "Epoch 50: 0.0013270238414406776\n",
      "Epoch 51: 0.0016993570607155561\n",
      "Epoch 52: 0.0019185703713446856\n",
      "Epoch 53: 0.0020792048890143633\n",
      "Epoch 54: 0.002260389272123575\n",
      "Epoch 55: 0.0024106246419250965\n",
      "Epoch 56: 0.0023768434766680002\n",
      "Epoch 57: 0.0020394055172801018\n",
      "Epoch 58: 0.0014327686512842774\n",
      "Epoch 59: 0.000751218874938786\n",
      "Epoch 60: 0.00023618359409738332\n",
      "Epoch 61: 3.2857045880518854e-05\n",
      "Epoch 62: 0.00011959340918110684\n",
      "Epoch 63: 0.00035023115924559534\n",
      "Epoch 64: 0.000563817739021033\n",
      "Epoch 65: 0.0006756013026461005\n",
      "Epoch 66: 0.0006926340283825994\n",
      "Epoch 67: 0.0006637443439103663\n",
      "Epoch 68: 0.0006196851609274745\n",
      "Epoch 69: 0.0005530218477360904\n",
      "Epoch 70: 0.00044339560554362833\n",
      "Epoch 71: 0.0002943642030004412\n",
      "Epoch 72: 0.00014451674360316247\n",
      "Epoch 73: 4.438942778506316e-05\n",
      "Epoch 74: 2.187332938774489e-05\n",
      "Epoch 75: 6.562269845744595e-05\n",
      "Epoch 76: 0.00013697778922505677\n",
      "Epoch 77: 0.00019667418382596225\n",
      "Epoch 78: 0.00022432625701185316\n",
      "Epoch 79: 0.00021985034982208163\n",
      "Epoch 80: 0.00019282623543404043\n",
      "Epoch 81: 0.00015276360500138253\n",
      "Epoch 82: 0.00010711073991842568\n",
      "Epoch 83: 6.381543789757416e-05\n",
      "Epoch 84: 3.177699545631185e-05\n",
      "Epoch 85: 1.7188936908496544e-05\n",
      "Epoch 86: 1.9694365619216114e-05\n",
      "Epoch 87: 3.2777650631032884e-05\n",
      "Epoch 88: 4.819049354409799e-05\n",
      "Epoch 89: 6.0202852182555944e-05\n",
      "Epoch 90: 6.635864701820537e-05\n",
      "Epoch 91: 6.561062764376402e-05\n",
      "Epoch 92: 5.720288390875794e-05\n",
      "Epoch 93: 4.191092011751607e-05\n",
      "Epoch 94: 2.370780930505134e-05\n",
      "Epoch 95: 8.904517017072067e-06\n",
      "Epoch 96: 2.5095532691921107e-06\n",
      "Epoch 97: 4.859724413108779e-06\n",
      "Epoch 98: 1.1719627764250617e-05\n",
      "Epoch 99: 1.7795588064473122e-05\n"
     ]
    }
   ],
   "source": [
    "# Loop\n",
    "epochs = 100\n",
    "adam_opt.zero_grad()\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Forward pass\n",
    "    y = mlp(x)\n",
    "    # Compute loss\n",
    "    loss = ((y - y_true) ** 2).sum()\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update weights\n",
    "    adam_opt.step()\n",
    "    adam_opt.zero_grad()\n",
    "    # Print loss\n",
    "    print(f'Epoch {i}: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
